{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b09cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f850a0",
   "metadata": {},
   "source": [
    "Мы будем работать с данными агрегатора такси [Sigma Cabs](https://www.kaggle.com/datasets/arashnic/taxi-pricing-with-mobility-analytics). В зависимости от характеристик поездки требуется предсказать один из трех типов повышенного ценообразования: [1, 2, 3]. Таким образом, это поможет компании оптимально мэтчить такси и клиентов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3409864d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131662, 14)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sigma_cabs.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92f029cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trip_Distance</th>\n",
       "      <th>Type_of_Cab</th>\n",
       "      <th>Customer_Since_Months</th>\n",
       "      <th>Life_Style_Index</th>\n",
       "      <th>Confidence_Life_Style_Index</th>\n",
       "      <th>Destination_Type</th>\n",
       "      <th>Customer_Rating</th>\n",
       "      <th>Cancellation_Last_1Month</th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Surge_Pricing_Type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trip_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T0005689460</th>\n",
       "      <td>6.77</td>\n",
       "      <td>B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.42769</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>3.90500</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>46</td>\n",
       "      <td>60</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T0005689461</th>\n",
       "      <td>29.47</td>\n",
       "      <td>B</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.78245</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>3.45000</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>56</td>\n",
       "      <td>78</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T0005689464</th>\n",
       "      <td>41.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E</td>\n",
       "      <td>3.50125</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56</td>\n",
       "      <td>77</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T0005689465</th>\n",
       "      <td>61.56</td>\n",
       "      <td>C</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>3.45375</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52</td>\n",
       "      <td>74</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T0005689467</th>\n",
       "      <td>54.95</td>\n",
       "      <td>C</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.03453</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>3.40250</td>\n",
       "      <td>4</td>\n",
       "      <td>51.0</td>\n",
       "      <td>49</td>\n",
       "      <td>102</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Trip_Distance Type_of_Cab  Customer_Since_Months  \\\n",
       "Trip_ID                                                         \n",
       "T0005689460           6.77           B                    1.0   \n",
       "T0005689461          29.47           B                   10.0   \n",
       "T0005689464          41.58         NaN                   10.0   \n",
       "T0005689465          61.56           C                   10.0   \n",
       "T0005689467          54.95           C                   10.0   \n",
       "\n",
       "             Life_Style_Index Confidence_Life_Style_Index Destination_Type  \\\n",
       "Trip_ID                                                                      \n",
       "T0005689460           2.42769                           A                A   \n",
       "T0005689461           2.78245                           B                A   \n",
       "T0005689464               NaN                         NaN                E   \n",
       "T0005689465               NaN                         NaN                A   \n",
       "T0005689467           3.03453                           B                A   \n",
       "\n",
       "             Customer_Rating  Cancellation_Last_1Month  Var1  Var2  Var3  \\\n",
       "Trip_ID                                                                    \n",
       "T0005689460          3.90500                         0  40.0    46    60   \n",
       "T0005689461          3.45000                         0  38.0    56    78   \n",
       "T0005689464          3.50125                         2   NaN    56    77   \n",
       "T0005689465          3.45375                         0   NaN    52    74   \n",
       "T0005689467          3.40250                         4  51.0    49   102   \n",
       "\n",
       "             Gender  Surge_Pricing_Type  \n",
       "Trip_ID                                  \n",
       "T0005689460  Female                   2  \n",
       "T0005689461    Male                   2  \n",
       "T0005689464    Male                   2  \n",
       "T0005689465    Male                   3  \n",
       "T0005689467    Male                   2  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Занесем индекс колонку\n",
    "df = df.set_index('Trip_ID')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92ce233",
   "metadata": {},
   "source": [
    "Описание признаков:\n",
    "\n",
    "1. **Trip_ID**: ID for TRIP\n",
    "2. **Trip_Distance**: The distance for the trip requested by the customer\n",
    "3. **TypeofCab**: Category of the cab requested by the customer\n",
    "4. **CustomerSinceMonths**: Customer using cab services since n months; 0 month means current month\n",
    "5. **LifeStyleIndex**: Proprietary index created by Sigma Cabs showing lifestyle of the customer based on their behaviour\n",
    "6. **ConfidenceLifeStyle_Index**: Category showing confidence on the index mentioned above\n",
    "7. **Destination_Type**: Sigma Cabs divides any destination in one of the 14 categories.\n",
    "8. **Customer_Rating**: Average of life time ratings of the customer till date\n",
    "9. **CancellationLast1Month**: Number of trips cancelled by the customer in last 1 month\n",
    "10. **Var1**, **Var2** and **Var3**: Continuous variables masked by the company. Can be used for modelling purposes\n",
    "11. **Gender**: Gender of the customer\n",
    "\n",
    "**SurgePricingType**: Target (can be of 3 types)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ee46a0",
   "metadata": {},
   "source": [
    "### EDA \n",
    "Заполните пропуски в вещественных признаках медианой, а в категориальных - самым популярным классом. Изобразите марицу корреляций и выведите топ5 пар самых коррелированных признаков.\n",
    "\n",
    "Так как в сумме уникальных значений различных категориальных признаков окажется не супер-много, примените `One-Hot-Encoding` для них. Не забудьте в методе `pd.get_dummies` указать параметр `drop_first=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c75ddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code is here\n",
    "\n",
    "numeric = df.loc[:, df.dtypes!=np.object].columns\n",
    "categorical = df.loc[:,df.dtypes==np.object].columns\n",
    "\n",
    "for col in numeric:\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "    \n",
    "for col in categorical:\n",
    "    most = df.groupby(col).size().sort_values().index[-1]\n",
    "    df[col] = df[col].fillna(most)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4253acaf-06be-42d9-8050-0e83d09b4ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical:\n",
    "    one_hot = pd.get_dummies(df[col], prefix=col, drop_first=True)\n",
    "    df = pd.concat((df.drop(col, axis=1), one_hot), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "402a0754-0034-459c-bb5a-78077e3a703c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Absolute Correlations\n",
      "Var2                           Var3                             0.683437\n",
      "Confidence_Life_Style_Index_B  Confidence_Life_Style_Index_C    0.565692\n",
      "Trip_Distance                  Life_Style_Index                 0.468332\n",
      "Type_of_Cab_B                  Type_of_Cab_C                    0.416698\n",
      "Surge_Pricing_Type             Type_of_Cab_D                    0.333639\n",
      "Type_of_Cab_B                  Type_of_Cab_D                    0.328262\n",
      "Life_Style_Index               Var3                             0.303324\n",
      "Customer_Rating                Var2                             0.302968\n",
      "Type_of_Cab_B                  Type_of_Cab_E                    0.248929\n",
      "Trip_Distance                  Var3                             0.231706\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def get_redundant_pairs(df):\n",
    "    pairs_to_drop = set()\n",
    "    cols = df.columns\n",
    "    for i in range(0, df.shape[1]):\n",
    "        for j in range(0, i+1):\n",
    "            pairs_to_drop.add((cols[i], cols[j]))\n",
    "    return pairs_to_drop\n",
    "\n",
    "def get_top_abs_correlations(df, n=5):\n",
    "    au_corr = df.corr().abs().unstack()\n",
    "    labels_to_drop = get_redundant_pairs(df)\n",
    "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "    return au_corr[0:n]\n",
    "\n",
    "print(\"Top Absolute Correlations\")\n",
    "print(get_top_abs_correlations(df, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286cdf91",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31ae953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2022)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c651dbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop('Surge_Pricing_Type', axis=1), df['Surge_Pricing_Type']\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, \n",
    "                                                     test_size=0.2, \n",
    "                                                     shuffle=True, \n",
    "                                                     random_state=2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da04c89b",
   "metadata": {},
   "source": [
    "**Задание 1.** Обучите One-vs-Rest Logreg. Не забудьте в шаг добавить стандартизацию данных (через `StandardScaler`) Посчитайте precision, recall, f1-score и усредните по всем классам с помощью micro, macro и weighted avg. Здесь и далее округляйте до 3 знака после запятой.\n",
    "\n",
    "Чтобы отдельно и долго не вычислять метрики, можно воспользоваться `classification_report` из `sklearn.metrics`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0532f126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('one_vs_all',\n",
       "                 OneVsRestClassifier(estimator=LogisticRegression()))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "### Your code is here\n",
    "\n",
    "pipeline = Pipeline([('scaler', StandardScaler()), ('one_vs_all', OneVsRestClassifier(LogisticRegression()))])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7a53403-9505-421e-aaef-566240510833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.723     0.542     0.619      5372\n",
      "           2      0.636     0.834     0.722     11349\n",
      "           3      0.741     0.571     0.645      9612\n",
      "\n",
      "    accuracy                          0.679     26333\n",
      "   macro avg      0.700     0.649     0.662     26333\n",
      "weighted avg      0.692     0.679     0.673     26333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, pipeline.predict(X_test), digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6100a2ac",
   "metadata": {},
   "source": [
    "Подберите оптимальные гиперпараметры модели с помощью `GridSearchCV()` из предложенных. Для лучшего набора гиперпараметров посчитайте те же самые метрики. Валидировать параметры необходимо по `accuracy`. В этот раз проведем настояющую процедуру Кросс-Валидации! \n",
    "\n",
    "Для этого в метод `fit` передадим тренировочную часть наших данных, в параметр `cv` ничего не будем передавать (по дефолту 5-fold Кросс-Валидация будет проведена), а итоговые метрики замерим на тесте!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21ff0cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'one_vs_all__estimator__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "              'one_vs_all__estimator__C': [0.001, 0.01, 0.1, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83f58cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('one_vs_all',\n",
       "                                        OneVsRestClassifier(estimator=LogisticRegression()))]),\n",
       "             param_grid={'one_vs_all__estimator__C': [0.001, 0.01, 0.1, 1],\n",
       "                         'one_vs_all__estimator__penalty': ['l1', 'l2',\n",
       "                                                            'elasticnet']})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Your code is here\n",
    "\n",
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV\n",
    "\n",
    "test_fold = [0 if x in X_train.index else -1 for x in X.index]\n",
    "ps = PredefinedSplit(test_fold)\n",
    "\n",
    "search = GridSearchCV(pipeline, param_grid)\n",
    "\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d42599d4-0dbf-42ca-8ad0-093fb5aa3f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.742     0.534     0.621      5372\n",
      "           2      0.635     0.839     0.723     11349\n",
      "           3      0.742     0.576     0.649      9612\n",
      "\n",
      "    accuracy                          0.681     26333\n",
      "   macro avg      0.706     0.650     0.664     26333\n",
      "weighted avg      0.696     0.681     0.675     26333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, search.predict(X_test), digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde7b9f8",
   "metadata": {},
   "source": [
    "Изобразите три калибровочные кривые для Logistic Classifier: 0-vs-rest, 1-vs-rest, 2-vs-rest. Хорошо ли откалиброван обученный классификатор? \n",
    "\n",
    "Заметьте, что `predict_proba` возвращает список из вероятностей для всех наших классов!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aecce37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code is here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3dcbb5",
   "metadata": {},
   "source": [
    "**Задание 2.** Обучите логистическую регрессию с гиперпараметрами из первого задания на полиномиальных признаках до 4 степени. Сравните метрики с первым заданием.\n",
    "\n",
    "\n",
    "Пример: Пусть у нас был единственный признак \n",
    "\n",
    "$$\n",
    "d_j = [1, 2, 3, 4]\n",
    "$$\n",
    "\n",
    "Тогда полиномиальные признаки до 4 степени от такого будут иметь вид:\n",
    "\n",
    "$$\n",
    "d_j^1 = [1, 2, 3, 4]\n",
    "$$\n",
    "\n",
    "$$\n",
    "d_j^2 = [1, 4, 9, 16]\n",
    "$$\n",
    "\n",
    "$$\n",
    "d_j^3 = [1, 8, 27, 64]\n",
    "$$\n",
    "\n",
    "$$\n",
    "d_j^4 = [1, 16, 81, 256]\n",
    "$$\n",
    "\n",
    "P.S. Бинарные колонки нет смысла возводить в какие-то степени, поэтому возьмем исключительно вещественные из базовых. \n",
    "\n",
    "Для этого можно воспользоваться классическим циклом (или уроком из занятия про `Sberbank Housing Market`). Положите модифицированный датасет в переменную `X_polinomial`!\n",
    "\n",
    "P.S.S Зачастую еще, создаваю полиномиальные фичи, учитывают \"пересечения\" признаков, то есть, например, из векторов признаков $d_j, d_i$ генерируют не просто новые степени $d_j^2, d_i^2, d_j^3, d_i^3...$, а еще и признаки вида $d_j \\cdot d_i, d_j^2 \\cdot d_i, d_j \\cdot d_i^2...$, но здесь ограничьтесь просто степенями!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a6789cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Создание полиномиальных признаков\n",
    "\n",
    "X_polinomial = X.copy()\n",
    "\n",
    "\n",
    "### Your code is here\n",
    "\n",
    "for col in numeric:\n",
    "    if col != 'Surge_Pricing_Type':\n",
    "        for power in [2, 3, 4]:\n",
    "            to_add = (X_polinomial[col]**power).to_frame().rename({col: f'{col}_{power}'}, axis=1)\n",
    "            X_polinomial = pd.concat((X_polinomial, to_add), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ac29559",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pol_train, X_pol_test, y_train, y_test  = train_test_split(X_polinomial, y, \n",
    "                                                             test_size=0.2, \n",
    "                                                             shuffle=True, \n",
    "                                                             random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7535371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.748     0.532     0.622      5372\n",
      "           2      0.636     0.837     0.723     11349\n",
      "           3      0.741     0.584     0.653      9612\n",
      "\n",
      "    accuracy                          0.682     26333\n",
      "   macro avg      0.708     0.651     0.666     26333\n",
      "weighted avg      0.697     0.682     0.677     26333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Your code is here\n",
    "\n",
    "search.fit(X_pol_train, y_train)\n",
    "\n",
    "print(classification_report(y_test, search.predict(X_pol_test), digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec071a2",
   "metadata": {},
   "source": [
    "По аналогии с первым заданием изобразите три калибровочные кривые. Стало ли лучше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "857886a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code is here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb60230",
   "metadata": {},
   "source": [
    "**Задание 3.** Обучите на датасете без полиномиальных признаков One-vs-One `SGDClassifier` из `sklearn.linear_model`, который использует стохастический градиентный спуск (узнаете о нем позже) и может обучать как `SVM`, так и, например, `LogReg`, если указать в качестве параметра `loss` либо `hinge`, либо `log` соответственно!\n",
    "\n",
    "Посчитайте precision, recall, f1-score и усредните по всем классам с помощью micro, macro и weighted avg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2b8c2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, \n",
    "                                                     test_size=0.2, \n",
    "                                                     shuffle=True, \n",
    "                                                     random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f3d52cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.737     0.524     0.612      5372\n",
      "           2      0.625     0.870     0.728     11349\n",
      "           3      0.758     0.531     0.625      9612\n",
      "\n",
      "    accuracy                          0.676     26333\n",
      "   macro avg      0.707     0.642     0.655     26333\n",
      "weighted avg      0.697     0.676     0.667     26333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "### Your code is here\n",
    "\n",
    "pipeline = Pipeline([('scaler', StandardScaler()), ('one_vs_one', OneVsOneClassifier(SGDClassifier(loss='hinge')))])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(y_test, pipeline.predict(X_test), digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56ef333",
   "metadata": {},
   "source": [
    "Подберите оптимальные гиперпараметры модели с помощью `GridSearchCV()`. При этом переберите всевозможные функции потерь. Таким образом, при `loss = 'hinge'`, мы обучим SVM, при `loss = 'log'` мы обучим логистическую регрессию и т.д.\n",
    "\n",
    "Используйте прием с Кросс-Валидацией при подборе параметров, как ранее, а также замерьте метрики на тесте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "526826b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'one_vs_one__estimator__loss': ['hinge', 'log', 'modified_huber'],\n",
    "              'one_vs_one__estimator__penalty': ['l1', 'l2'],\n",
    "              'one_vs_one__estimator__alpha': [0.001, 0.01, 0.1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12f0400f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.737     0.524     0.612      5372\n",
      "           2      0.625     0.870     0.728     11349\n",
      "           3      0.758     0.531     0.625      9612\n",
      "\n",
      "    accuracy                          0.676     26333\n",
      "   macro avg      0.707     0.642     0.655     26333\n",
      "weighted avg      0.697     0.676     0.667     26333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Your code is here\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "search = GridSearchCV(pipeline, param_grid)\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(y_test, pipeline.predict(X_test), digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed95cbe",
   "metadata": {},
   "source": [
    "Можно ли однозначно сказать, какой подход оказался лучше: One-vs-Rest или One-vs-One?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
